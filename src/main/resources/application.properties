spring.application.name=ugate-service
application.external.media-service-name=syndicat


# SERVER
server.port=8091
spring.docker.compose.enabled=false
springdoc.swagger-ui.path=/swagger-ui.html
springdoc.api-docs.path=/v3/api-docs
server.forward-headers-strategy=framework
logging.level.org.springframework.security=DEBUG
logging.level.org.springframework.security.oauth2=DEBUG

# POSTGRESQL (R2DBC) 
spring.r2dbc.url=r2dbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:newdb2}
spring.r2dbc.username=${DB_USERNAME:postgres}
spring.r2dbc.password=${DB_PASSWORD:postgres}
# spring.r2dbc.username=master
# spring.r2dbc.password=Azerty1234
# Nombre de connexions ouvertes au démarrage
spring.r2dbc.pool.initial-size=1
# MAX connexions simultanées vers PostgreSQL
spring.r2dbc.pool.max-size=5
# Temps max d’attente pour obtenir une connexion
spring.r2dbc.pool.max-acquire-time=30s
# Libère les connexions inutilisées
spring.r2dbc.pool.max-idle-time=30m
# Recycle les connexions (évite les leaks)
spring.r2dbc.pool.max-life-time=10m
# Retry si le pool est saturé
spring.r2dbc.pool.acquire-retry=3
# Vérification de la connexion
spring.r2dbc.pool.validation-query=SELECT 1

# SQL INIT
spring.sql.init.mode=always

# Configuration Liquibase
spring.liquibase.change-log=classpath:db/changelog/db.changelog-master.xml
spring.liquibase.url=jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5432}/${DB_NAME:newdb2}
spring.liquibase.user=${DB_USERNAME:postgres}
spring.liquibase.password=${DB_PASSWORD:postgres}
#  spring.liquibase.user=master
#  spring.liquibase.password=Azerty1234

# REDIS
spring.data.redis.host=${REDIS_HOST:168.119.122.86}
spring.data.redis.port=${REDIS_PORT:7000}
spring.data.redis.password=${REDIS_PASSWORD:Azerty1234*}
spring.data.redis.cluster.enabled=false

# KAFKA
spring.kafka.bootstrap-servers=${KAFKA_HOST:168.119.122.86}:${KAFKA_PORT:9092}

# KAFKA CONSUMER
spring.kafka.consumer.auto-offset-reset=earliest
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.springframework.kafka.support.serializer.JsonDeserializer
spring.kafka.consumer.properties.spring.json.trusted.packages=*

# KAFKA PRODUCER
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer

# CUSTOM CONFIG
application.external.stock-service-url= http://${EXTERNAL_HOST:168.119.122.86}:8081
application.kafka.topics.product-events=test-topic

management.endpoints.web.exposure.include=health,info,prometheus
management.endpoint.health.probes.enabled=true
management.metrics.export.prometheus.enabled=true

# RESILIENCE4J
resilience4j.circuitbreaker.instances.stock-service.failureRateThreshold=50
resilience4j.circuitbreaker.instances.stock-service.waitDurationInOpenState=5s
resilience4j.circuitbreaker.instances.stock-service.slidingWindowSize=5

# API Externe

#Media Service
application.external.media-service-url=https://media-service.pynfi.com

# Authentication Service
application.external.auth-service-url=https://auth-service.pynfi.com/
jwt.secret=404E635266556A586E3272357538782F413F4428472B4B6250645367566B5970

#Notification Service
application.external.notification-service-url=https://notification-service.pynfi.com
application.external.notification-service-token=VOTRE_TOKEN_ICI
application.external.notification-invite-template-id=123